# Default values for kube-prometheus-stack.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

## Install Prometheus Operator CRDs
##
crds:
  enabled: true

## Configuration for alertmanager
## ref: https://prometheus.io/docs/alerting/alertmanager/
##
alertmanager:
  ## Deploy alertmanager
  ##
  enabled: true

  ingress:
    enabled: true

    # For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName
    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
    ingressClassName: nginx

    # annotations: -> template

    ## Override ingress to a different defined port on the service
    # servicePort: 8081
    ## Override ingress to a different service then the default, this is useful if you need to
    ## point to a specific instance of the alertmanager (eg kube-prometheus-stack-alertmanager-0)
    # serviceName: kube-prometheus-stack-alertmanager-0

    ## Hosts must be provided if Ingress is enabled.
    ##
    # hosts: -> template

    ## TLS configuration for Alertmanager Ingress
    ## Secret must be manually created in the namespace
    ##
    # tls: -> template

  ## Settings affecting alertmanagerSpec
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#alertmanagerspec
  ##
  alertmanagerSpec:
    ## Storage is the definition of how storage will be used by the Alertmanager instances.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/storage.md
    ##
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: nfs-client-hdd-0
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 1Gi
          # selector: {}

    ## Define resources requests and limits for single Pods.
    ## ref: https://kubernetes.io/docs/user-guide/compute-resources/
    ##
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"

## Using default values from https://github.com/grafana/helm-charts/blob/main/charts/grafana/values.yaml
##
grafana:
  enabled: false

  ## ForceDeployDatasources Create datasource configmap even if grafana deployment has been disabled
  ##
  forceDeployDatasources: true

  ## ForceDeployDashboard Create dashboard configmap even if grafana deployment has been disabled
  ##
  forceDeployDashboards: true

  ## Deploy default dashboards
  ##
  defaultDashboardsEnabled: true

  ## Timezone for the default dashboards
  ## Other options are: browser or a specific timezone, i.e. Europe/Luxembourg
  ##
  defaultDashboardsTimezone: browser

  ## Editable flag for the default dashboards
  ##
  defaultDashboardsEditable: false

  # sidecar: -> template

## Configuration for kube-state-metrics subchart
##
kube-state-metrics:
  resources:
    requests:
      memory: "64Mi"
      cpu: "50m"
    limits:
      memory: "128Mi"
      cpu: "100m"

## Deploy node exporter as a daemonset to all nodes
##
nodeExporter:
  enabled: true
  operatingSystems:
    linux:
      enabled: true
    aix:
      enabled: false
    darwin:
      enabled: false

## Configuration for prometheus-node-exporter subchart
##
prometheus-node-exporter:
  resources:
    requests:
      memory: "64Mi"
      cpu: "50m"
    limits:
      memory: "128Mi"
      cpu: "100m"

## Manages Prometheus and Alertmanager components
##
prometheusOperator:
  enabled: true

  ## Number of old replicasets to retain ##
  ## The default value is 10, 0 will garbage-collect old replicasets ##
  revisionHistoryLimit: 1

  ## Admission webhook support for PrometheusRules resources added in Prometheus Operator 0.30 can be enabled to prevent incorrectly formatted
  ## rules from making their way into prometheus and potentially preventing the container from starting
  admissionWebhooks:
    enabled: true
    patch:
      enabled: true
      resources:
        requests:
          memory: "64Mi"
          cpu: "50m"
        limits:
          memory: "128Mi"
          cpu: "100m"
    # Use certmanager to generate webhook certs
    certManager:
      enabled: false
      # self-signed root certificate
      rootCert:
        duration: "" # default to be 5y
      admissionCert:
        duration: "" # default to be 1y
      issuerRef:
        name: "ca-cluster-issuer"
        kind: "ClusterIssuer"

  ## Resource limits & requests
  ##
  resources:
    requests:
      memory: "64Mi"
      cpu: "50m"
    limits:
      memory: "128Mi"
      cpu: "100m"

  ## Prometheus-config-reloader
  ##
  prometheusConfigReloader:
    # add prometheus config reloader liveness and readiness probe. Default: false
    enableProbe: false

    # resource config for prometheusConfigReloader
    resources:
      requests:
        memory: "64Mi"
        cpu: "10m"
      limits:
        memory: "128Mi"
        cpu: "50m"

  ## Set a Label Selector to filter watched prometheus and prometheusAgent
  ##
  prometheusInstanceSelector: ""

  ## Set a Label Selector to filter watched alertmanager
  ##
  alertmanagerInstanceSelector: ""

## Deploy a Prometheus instance
##
prometheus:
  enabled: true
  ingress:
    enabled: true

    # For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName
    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
    ingressClassName: nginx

    # annotations:  -> template

    ## Redirect ingress to an additional defined port on the service
    # servicePort: 8081

    ## Hostnames.
    ## Must be provided if Ingress is enabled.
    ##
    # hosts:
    #   - prometheus.domain.com
    #hosts:  -> template

    ## TLS configuration for Prometheus Ingress
    ## Secret must be manually created in the namespace
    ##
    #tls: -> template

  serviceMonitor:
    ## If true, create a serviceMonitor for prometheus
    ##
    selfMonitor: true

    #   relabel configs to apply to samples before ingestion.
    ## ## solve https://github.com/prometheus-community/helm-charts/issues/4221
    relabelings:
      - targetLabel: cluster
        replacement: "prometheus"

  ## Settings affecting prometheusSpec
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#prometheusspec
  ##
  prometheusSpec:
    ## EnableAdminAPI enables Prometheus the administrative HTTP API which includes functionality such as deleting time series.
    ## This is disabled by default.
    ## ref: https://prometheus.io/docs/prometheus/latest/querying/api/#tsdb-admin-apis
    ##
    enableAdminAPI: false

    serviceMonitorSelector:
      matchLabels:
        app.kubernetes.io/managed-by: Helm

    ## Resource limits & requests
    ##
    resources:
      requests:
        memory: "512Mi"
        cpu: "100m"
      limits:
        memory: "1Gi"
        cpu: "200m"

    ## Prometheus StorageSpec for persistent data
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/storage.md
    ##
    storageSpec:
      ## Using PersistentVolumeClaim
      ##
      volumeClaimTemplate:
        spec:
          storageClassName: nfs-client-hdd-0
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 1Gi
        #  selector: {}

    ## Using tmpfs volume
    ##
    #  emptyDir:
    #    medium: Memory

## Setting to true produces cleaner resource names, but requires a data migration because the name of the persistent volume changes. Therefore this should only be set once on initial installation.
##
cleanPrometheusOperatorObjectNames: true
